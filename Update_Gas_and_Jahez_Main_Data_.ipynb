{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ridrisa/COD_Bot/blob/main/Update_Gas_and_Jahez_Main_Data_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OqDQiNYIQA8j"
      },
      "source": [
        "# Updating Master Jahez and Maser Gas\n",
        "\n",
        "---\n",
        "\n",
        "The below Script Updates Master Jahez and Master Gas\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vv1x8o2pPwoH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "d9bb57ce-0592-442e-ed40-e8ea9d69130d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-665909ea4eb4>:35: DtypeWarning: Columns (1,3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  return pd.read_csv(StringIO(data))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Login successful for barqkhadamatftacc\n",
            "Data for 02/10/2024 12:00 AM processed.\n",
            "Data for 02/11/2024 12:00 AM processed.\n",
            "Login successful for barqkhadamatruhacc\n",
            "Data for 02/10/2024 12:00 AM processed.\n",
            "Data for 02/11/2024 12:00 AM processed.\n",
            "Data processing complete. Files saved.\n",
            "Data loaded and deduplicated in BigQuery\n",
            "Request for downloading bills Excel file was successful!\n",
            "Excel file has been downloaded as 'bills_data.xlsx'\n",
            "Request was successful.\n",
            "<!doctype html>\n",
            "<html>\n",
            "<head>\n",
            "<meta name=\"chromevox\" content-script=\"no\">\n",
            "<link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/icon?family=Material+Icons\" nonce=\"T3hvplqPaXGYgvwkjzuPJQ\"><link rel=\"stylesheet\" href=\"/static/macros/client/css/3057681068-mae_html_css_ltr.css\">\n",
            "<script type=\"text/javascript\" src=\"/static/macros/client/js/2643123624-warden_bin_i18n_warden.js\"></script>\n",
            "</head>\n",
            "<body>\n",
            "<table id=\"warning-bar-table\" class=\"full_size\" cellspacing=\"0\" cellpadding=\"0\"><tr><td><div id=\"warning\" class=\"warning-bar\"></div></td></tr><tr><td style=\"height: 100%\"><iframe id=\"sandboxFrame\" allow=\"accelerometer *; ambient-light-sensor *; autoplay *; camera *; clipboard-read *; clipboard-write *; encrypted-media *; fullscreen *; geolocation *; gyroscope *; magnetometer *; microphone *; midi *; payment *; picture-in-picture *; screen-wake-lock *; speaker *; sync-xhr *; usb *; web-share *; vibrate *; vr *\" sandbox=\"allow-downloads allow-forms allow-modals allow-popups allow-popups-to-escape-sandbox allow-same-origin allow-scripts allow-top-navigation-by-user-activation allow-storage-access-by-user-activation\">\n",
            "</iframe>\n",
            "</td></tr></table><script nonce=\"bzNSPEYMaHY687XeLqXzzA\">\n",
            "(function() {\n",
            "var el = document.getElementById('sandboxFrame');\n",
            "el.onload = function() {\n",
            "goog.script.init(\"\\x7b\\x22functionNames\\x22:\\x5b\\x22main\\x22,\\x22setNumberFormats\\x22,\\x22removeDuplicates\\x22,\\x22deleteFromSummaryDownwards\\x22,\\x22fixDash\\x22,\\x22deleteColumns\\x22,\\x22doGet\\x22\\x5d,\\x22sandboxMode\\x22:\\x22IFRAME_SANDBOX\\x22,\\x22callbackTimeout\\x22:390000,\\x22deploymentId\\x22:\\x22AKfycbywdpV9dMN_W_mcSE5J31_MWsFYoUpt3QJlmUmssbyEolQsB5pUUti3k08G2cE96IMD\\x22,\\x22eei\\x22:\\x22\\x22,\\x22sandboxHost\\x22:\\x22https:\\/\\/n-wtc2ibjnz6zzzx7a2fzkyswufrafrcxvqrjxliq-0lu-script.googleusercontent.com\\x22,\\x22clientSideProperties\\x22:\\x7b\\x22google.script.sandbox.mode\\x22:\\x22IFRAME_SANDBOX\\x22,\\x22google.script.host.origin\\x22:\\x22https:\\/\\/docs.google.com\\x22\\x7d,\\x22actionPrefix\\x22:\\x22\\/macros\\/s\\/AKfycbywdpV9dMN_W_mcSE5J31_MWsFYoUpt3QJlmUmssbyEolQsB5pUUti3k08G2cE96IMD\\x22,\\x22userHtml\\x22:\\x22\\x3ch1\\x3eError Occurred\\x3c\\\\\\/h1\\x3e\\x3cp\\x3eError details: Service Spreadsheets timed out while accessing document with id 15JYUG5RB-Q2LKqw-30pNAZxWcdCKyZ0igzKImikC8H8.\\x3c\\\\\\/p\\x3e\\x22,\\x22ncc\\x22:\\x22\\x7b\\\\\\x22awhs\\\\\\x22:true\\x7d\\x22\\x7d\", \"\", undefined, true , false  , \"false\", \"https:\\/\\/n-wtc2ibjnz6zzzx7a2fzkyswufrafrcxvqrjxliq-0lu-script.googleusercontent.com\", \"\\/\\/drive.google.com\\/abuse?id\\x3dAKkXjoz9gjWzjtemqOxdOzDt9a0ln0BH0B7pwNAZD-JI9hVNQTm7wnc_AMutkIx8-SSDg6OdmycQ3fCC04op7THwTjWj13VZe_NL2fWD%3A0\");}\n",
            "el.src = 'https:\\/\\/n-wtc2ibjnz6zzzx7a2fzkyswufrafrcxvqrjxliq-0lu-script.googleusercontent.com\\/userCodeAppPanel';\n",
            "}());\n",
            "</script>\n",
            "</body>\n",
            "</html>\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# @title Update Master Jahez and Gas valid till 25 feb\n",
        "from google.cloud import storage\n",
        "from google.cloud import bigquery\n",
        "from datetime import datetime, timedelta\n",
        "from google.oauth2 import service_account\n",
        "import pandas as pd\n",
        "import requests\n",
        "import os\n",
        "from io import BytesIO, StringIO\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "\n",
        "\n",
        "credentials_path = '/content/drive/MyDrive/My_Colab_Enviroment/Credentials.json'\n",
        "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = credentials_path\n",
        "\n",
        "# Load credentials\n",
        "google_credentials = service_account.Credentials.from_service_account_file(credentials_path)\n",
        "# Function to parse dates with multiple formats\n",
        "def parse_date(date_str):\n",
        "    for fmt in (\"%m/%d/%Y %I:%M:%S %p\", \"%Y-%m-%d %H:%M:%S\"):  # Add or adjust formats as needed\n",
        "        try:\n",
        "            return datetime.strptime(date_str, fmt)\n",
        "        except ValueError:\n",
        "            continue\n",
        "    raise ValueError('no valid date format found for: ' + date_str)\n",
        "\n",
        "# Initialize Google Cloud Storage client\n",
        "storage_client = storage.Client(credentials=google_credentials)\n",
        "bucket_name = 'ramiz_python_scripts'\n",
        "bucket = storage_client.get_bucket(bucket_name)\n",
        "\n",
        "# Function to read CSV file from Google Cloud Storage\n",
        "def read_csv_from_gcs(filename):\n",
        "    blob = bucket.blob(filename)\n",
        "    data = blob.download_as_text()\n",
        "    return pd.read_csv(StringIO(data))\n",
        "\n",
        "# Function to write DataFrame to CSV in Google Cloud Storage\n",
        "def write_csv_to_gcs(df, filename):\n",
        "    blob = bucket.blob(filename)\n",
        "    blob.upload_from_string(df.to_csv(index=False), 'text/csv')\n",
        "\n",
        "# Login credentials and URLs\n",
        "credentials = [\n",
        "    {\"username\": \"barqkhadamatftacc\", \"password\": \"BARQ_2030_KSA\"},\n",
        "    {\"username\": \"barqkhadamatruhacc\", \"password\": \"BARQ_2030_KSA\"}\n",
        "]\n",
        "login_url = \"https://www.saned.io/Login\"\n",
        "export_url = \"https://www.saned.io/payment/orgExcelExport\"\n",
        "\n",
        "# Create a session\n",
        "session = requests.Session()\n",
        "\n",
        "# Date setup\n",
        "yesterday = datetime.now() - timedelta(days=1)\n",
        "start_date = yesterday.replace(hour=0, minute=0, second=0, microsecond=0)\n",
        "end_date = datetime.now().replace(hour=23, minute=59, second=59, microsecond=999999)\n",
        "\n",
        "# Read the original master CSV file from GCS\n",
        "master_df = read_csv_from_gcs('jahez_master.csv')\n",
        "\n",
        "# Function to check if a row is new\n",
        "def is_new_entry(row, existing_dids):\n",
        "    return row['DID'] not in existing_dids\n",
        "\n",
        "# Get a set of existing DIDs\n",
        "existing_dids = set(master_df['DID'])\n",
        "\n",
        "# Loop through each credential\n",
        "for credential in credentials:\n",
        "    # Login request\n",
        "    login_data = {\"username\": credential[\"username\"], \"password\": credential[\"password\"]}\n",
        "    response = session.post(login_url, data=login_data)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        print(\"Login successful for\", credential[\"username\"])\n",
        "        current_date = start_date\n",
        "        while current_date <= end_date:\n",
        "            # Export request setup\n",
        "            current_date_str = current_date.strftime(\"%m/%d/%Y %I:%M %p\")\n",
        "            query_params = {\n",
        "                \"fromDate\": current_date_str,\n",
        "                \"toDate\": (current_date + timedelta(days=1)).strftime(\"%m/%d/%Y %I:%M %p\"),\n",
        "                \"driverId\": \"\",\n",
        "                \"driverSettled\": \"\",\n",
        "                \"isDriversettled\": \"all\",\n",
        "                \"settledDate\": \"false\"\n",
        "            }\n",
        "\n",
        "            export_response = session.get(export_url, params=query_params)\n",
        "            if export_response.status_code == 200:\n",
        "                buffer = BytesIO(export_response.content)\n",
        "                exported_df = pd.read_excel(buffer, skiprows=2)\n",
        "\n",
        "                # Data processing\n",
        "                exported_df[\"Dispatch Time\"] = pd.to_datetime(exported_df[\"Dispatch Time\"], format=\"%d-%m-%Y %I:%M:%S %p\")\n",
        "                exported_df[\"Saudi Date\"] = exported_df[\"Dispatch Time\"] + timedelta(hours=3)\n",
        "                exported_df[\"Saudi Date\"] = exported_df[\"Saudi Date\"].dt.strftime(\"%m/%d/%Y %I:%M:%S %p\")\n",
        "                exported_df[\"User\"] = credential[\"username\"]\n",
        "\n",
        "                new_entries = exported_df[exported_df.apply(lambda row: is_new_entry(row, existing_dids), axis=1)]\n",
        "                duplicates = exported_df[~exported_df.apply(lambda row: is_new_entry(row, existing_dids), axis=1)]\n",
        "\n",
        "                master_df = pd.concat([master_df, new_entries], ignore_index=True)\n",
        "                print(f\"Data for {current_date_str} processed.\")\n",
        "            else:\n",
        "                print(\"Export request failed. Status code:\", export_response.status_code)\n",
        "\n",
        "            current_date += timedelta(days=1)\n",
        "    else:\n",
        "        print(\"Login failed for\", credential[\"username\"], \"Status code:\", response.status_code)\n",
        "\n",
        "# Final processing before saving\n",
        "master_df[\"Saudi Date\"] = master_df[\"Saudi Date\"].apply(lambda x: parse_date(x) if not pd.isna(x) else x)\n",
        "master_df[\"Saudi Date\"] = master_df[\"Saudi Date\"].dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "\n",
        "# Remove unnecessary columns and deduplicate\n",
        "master_df.drop(columns=['No'], inplace=True)\n",
        "master_df = master_df.drop_duplicates(subset='DID', keep='first')\n",
        "\n",
        "# Write the updated master data to GCS\n",
        "write_csv_to_gcs(master_df, 'jahez_master.csv')\n",
        "\n",
        "print(\"Data processing complete. Files saved.\")\n",
        "\n",
        "def load_data_to_bigquery():\n",
        "    client = bigquery.Client(project='looker-barqdata-2030',credentials=google_credentials)\n",
        "    dataset_id = 'master_saned'  # Your dataset ID\n",
        "    table_id = 'jahez'  # Your table ID\n",
        "    destination = f\"{dataset_id}.{table_id}\"\n",
        "    schema = [\n",
        "        bigquery.SchemaField(\"DID\", \"INT64\"),\n",
        "        bigquery.SchemaField(\"Ref_ID\", \"STRING\"),\n",
        "        bigquery.SchemaField(\"Driver_Name\", \"STRING\"),\n",
        "        bigquery.SchemaField(\"Driver_Username\", \"STRING\"),\n",
        "        bigquery.SchemaField(\"Driver_ID\", \"INT64\"),\n",
        "        bigquery.SchemaField(\"Amount\", \"FLOAT64\"),\n",
        "        bigquery.SchemaField(\"Price\", \"FLOAT64\"),\n",
        "        bigquery.SchemaField(\"Driver_Debit_Amount\", \"FLOAT64\"),\n",
        "        bigquery.SchemaField(\"Driver_Credit_Amount\", \"FLOAT64\"),\n",
        "        bigquery.SchemaField(\"Is_Free_Order\", \"INT64\"),\n",
        "        bigquery.SchemaField(\"Dispatch_Time\", \"DATETIME\"),\n",
        "        bigquery.SchemaField(\"Subscriber\", \"STRING\"),\n",
        "        bigquery.SchemaField(\"Driver_Paid_Org\", \"BOOLEAN\"),\n",
        "        bigquery.SchemaField(\"Org_Settled\", \"BOOLEAN\"),\n",
        "        bigquery.SchemaField(\"Driver_Settled\", \"BOOLEAN\"),\n",
        "        bigquery.SchemaField(\"Saudi_Date\", \"DATETIME\"),\n",
        "        bigquery.SchemaField(\"User\", \"STRING\")\n",
        "    ]\n",
        "    job_config = bigquery.LoadJobConfig(\n",
        "        schema=schema,\n",
        "        skip_leading_rows=1,\n",
        "        source_format=bigquery.SourceFormat.CSV,\n",
        "        write_disposition=bigquery.WriteDisposition.WRITE_TRUNCATE,\n",
        "    )\n",
        "    uri = \"gs://ramiz_python_scripts/jahez_master.csv\"\n",
        "    load_job = client.load_table_from_uri(uri, destination, job_config=job_config)\n",
        "    load_job.result()  # Waits for the job to complete\n",
        "\n",
        "    # Deduplicate the data\n",
        "    query = \"\"\"\n",
        "    CREATE OR REPLACE TABLE `master_saned.jahez` AS\n",
        "    SELECT DISTINCT * FROM `master_saned.jahez`;\n",
        "    \"\"\"\n",
        "    query_job = client.query(query)\n",
        "    query_job.result()  # Waits for the job to complete\n",
        "\n",
        "    print(\"Data loaded and deduplicated in BigQuery\")\n",
        "\n",
        "# Call the function to execute the operations\n",
        "load_data_to_bigquery()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from datetime import date\n",
        "import requests\n",
        "import webbrowser\n",
        "import os\n",
        "import pandas as pd\n",
        "import gspread\n",
        "from oauth2client.service_account import ServiceAccountCredentials\n",
        "\n",
        "# Function to read data from a specific column in Google Sheets\n",
        "def read_column(sheet_id, sheet_name, column):\n",
        "    scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']\n",
        "    creds = ServiceAccountCredentials.from_json_keyfile_name(\"/content/drive/MyDrive/My_Colab_Enviroment/Credentials.json\", scope)\n",
        "    client = gspread.authorize(creds)\n",
        "\n",
        "    sheet = client.open_by_key(sheet_id)\n",
        "    worksheet = sheet.worksheet(sheet_name)\n",
        "    column_data = worksheet.col_values(ord(column.upper()) - 64)  # Convert column letter to number\n",
        "    return column_data\n",
        "\n",
        "# Function to append unique rows to Google Sheets\n",
        "def append_unique_rows(df, sheet_id, sheet_name, column_data):\n",
        "    scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']\n",
        "    creds = ServiceAccountCredentials.from_json_keyfile_name(\"/content/drive/MyDrive/My_Colab_Enviroment/Credentials.json\", scope)\n",
        "    client = gspread.authorize(creds)\n",
        "\n",
        "    sheet = client.open_by_key(sheet_id)\n",
        "    worksheet = sheet.worksheet(sheet_name)\n",
        "\n",
        "    unique_rows = df[~df[df.columns[0]].isin(column_data)]\n",
        "    if not unique_rows.empty:\n",
        "        worksheet.append_rows(unique_rows.values.tolist())\n",
        "\n",
        "# Variables from your existing script\n",
        "sheet_id = \"15JYUG5RB-Q2LKqw-30pNAZxWcdCKyZ0igzKImikC8H8\"\n",
        "sheet_name = \"Sheet1\"  # Replace with the actual name of your sheet\n",
        "\n",
        "\n",
        "# API request setup\n",
        "url = \"https://app.petroapp.com.sa/dashboard_api/download_bills_excel\"\n",
        "end_date = (date.today() + timedelta(days=1)).strftime(\"%Y/%m/%d\")\n",
        "download_params = {\n",
        "    \"dates\": f\"2024/02/09-{end_date}\",\n",
        "    \"order_by\": \"\",\n",
        "    \"limit\": 10,\n",
        "    \"page\": 1,\n",
        "    \"order_type\": \"\"\n",
        "}\n",
        "download_auth_token = \"eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJodHRwOi8vYXBwLnBldHJvYXBwLmNvbS5zYS9kYXNoYm9hcmRfYXBpL2xvZ2luIiwiaWF0IjoxNzA3NjY0NDg0LCJleHAiOjE3MDg4NzQwODQsIm5iZiI6MTcwNzY2NDQ4NCwianRpIjoiMG9FenJCYTBJS3ZuUWx3dSIsInN1YiI6Ijg4MTgyMSIsInBydiI6IjIzYmQ1Yzg5NDlmNjAwYWRiMzllNzAxYzQwMDg3MmRiN2E1OTc2ZjcifQ.OJT1gYQCK61GeD91rWUDtZjGaBpvPWn0R4WqcKcDcC8\"\n",
        "download_headers = {\n",
        "    \"Authorization\": f\"Bearer {download_auth_token}\",\n",
        "    \"Accept\": \"application/json\",\n",
        "    \"Accept-Encoding\": \"gzip, deflate, br\",\n",
        "    \"Accept-Language\": \"en-SA,en;q=0.9,ar-SA;q=0.8,ar;q=0.7,en-GB;q=0.6,en-US;q=0.5\",\n",
        "    \"Content-Type\": \"application/json\",\n",
        "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/116.0.0.0 Safari/537.36\"\n",
        "}\n",
        "\n",
        "# Make the GET request to download bills Excel file\n",
        "download_response = requests.get(url, params=download_params, headers=download_headers)\n",
        "if download_response.status_code == 200:\n",
        "    print(\"Request for downloading bills Excel file was successful!\")\n",
        "    excel_file_path = (\"bills_data.xlsx\")\n",
        "    with open(excel_file_path, \"wb\") as f:\n",
        "        f.write(download_response.content)\n",
        "    print(f\"Excel file has been downloaded as '{excel_file_path}'\")\n",
        "\n",
        "    # Process the downloaded Excel file\n",
        "    df = pd.read_excel(excel_file_path, skiprows=[0])  # Adjust skiprows as needed\n",
        "    df.fillna('', inplace=True)\n",
        "\n",
        "    # Read Column A from the Google Sheet\n",
        "    original_column_data = read_column(sheet_id, sheet_name, 'A')\n",
        "\n",
        "    # Append unique rows to the original sheet\n",
        "    append_unique_rows(df, sheet_id, sheet_name, original_column_data)\n",
        "else:\n",
        "    print(f\"Failed to get data for downloading. Status code: {download_response.status_code}\")\n",
        "\n",
        "urlscript=\"https://script.google.com/macros/s/AKfycbywdpV9dMN_W_mcSE5J31_MWsFYoUpt3QJlmUmssbyEolQsB5pUUti3k08G2cE96IMD/exec\"\n",
        "responsescript = requests.get(urlscript)\n",
        "\n",
        "# Checking if the request was successful\n",
        "if responsescript.status_code == 200:\n",
        "    print('Request was successful.')\n",
        "    display(HTML(responsescript.text))\n",
        "\n",
        "    # Printing the content of the request\n",
        "    print(responsescript.text)\n",
        "else:\n",
        "    print(f'Request failed with status code: {responsescript.status_code}')\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1EwilEUimi-YA4k-PlYsxAgyvMAQXCbJh",
      "authorship_tag": "ABX9TyPeLJQyykZ9moyWq8lWeG33",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}